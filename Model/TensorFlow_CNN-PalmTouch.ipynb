{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PalmTouch using a Convolutional Neural Network (TensorFlow)\n",
    "CNNs are the recent state-of-the-art method for image classification. As blobs are represented by low-resolution images, we implemented a CNNs using TensorFlow. We performed a grid search over the number of layers, filters and their sizes in steps of 1, the number of neurons in the fully connected layer in steps of 50, as well as activation functions and optimizers provided by TensorFlow. Our final network architecture is shown in Table 1 in the paper. We trained the CNN using AdaGrad as the optimizer with a batch size of 100 and used the Xavier initialization scheme to initialize the network weights. We initialized the biases with random values from a normal distribution. An exponential decay (rate = 0.2 in 1000 steps) was used to decrease the initial learning rate of 0.009. We used L2 Regularization to compensate overfitting by adding 0.01 of the weights to the cost function. Moreover, we used an early stopping approach as proposed by Caruana et al. to further avoid overfitting. While we experimented with batch normalization, this did not improve the overall accuracy. Our CNN achieved an accuracy of 99.58% (prec = 99.38% , rec = 99.28%) which is the highest of all presented approaches.\n",
    "\n",
    "The following code is based on an example for convolutional neural networks (https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflowFolder = \".\"\n",
    "STORAGE_NAME = 'CNN-PalmTouch'\n",
    "\n",
    "GPU_USE= '/gpu:0'\n",
    "DATA_PATH = './Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [    
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.python.framework import dtypes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import init_ops\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, images, labels, one_hot=False, dtype=dtypes.float32):\n",
    "        \"\"\"Construct a DataSet.\n",
    "        one_hot arg is used only if fake_data is true.    `dtype` can be either\n",
    "        `uint8` to leave the input as `[0, 255]`, or `float32` to rescale into\n",
    "        `[0, 1]`.\n",
    "        \"\"\"\n",
    "        dtype = dtypes.as_dtype(dtype).base_dtype\n",
    "        if dtype not in (dtypes.uint8, dtypes.float32):\n",
    "            raise TypeError('Invalid image dtype %r, expected uint8 or float32' % dtype)\n",
    "        assert images.shape[0] == labels.shape[0], ('images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        # Convert shape from [num examples, rows, columns, depth]\n",
    "        # to [num examples, rows*columns] (assuming depth == 1)\n",
    "        if dtype == dtypes.float32:\n",
    "            # Convert from [0, 255] -> [0.0, 1.0].\n",
    "            images = images.astype(np.float32)\n",
    "            images = np.multiply(images, 1.0 / 255.0)\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "    \n",
    "    def reset(self):\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._images[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(labels):\n",
    "    oh = np.zeros((labels.size, labels.max()+1))\n",
    "    oh[np.arange(labels.size), labels] = 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_sets(datapath, \n",
    "                   one_hot=False,\n",
    "                   dtype=dtypes.float32,\n",
    "                   split = (80, 20),):\n",
    "    \n",
    "    OH_TASKS = [\"TAP\", \"DRAG\", \"SCROLL\"]\n",
    "    TH_TASKS = [\"PINCH\", \"ROTATE\"]\n",
    "    PALM_TASK = [\"PALM\"]\n",
    "    \n",
    "    # Reading pickles from disk\n",
    "    df_train = \"\"\n",
    "    for i in range(1, 19):\n",
    "        print(\"Adding P%i to the training set.\" % (i))\n",
    "        df_temp = pd.read_pickle(datapath + \"p\" + str(i) + \"_blobimages.pkl\", compression=\"gzip\")\n",
    "        if (type(df_train) is str):\n",
    "            df_train = df_temp\n",
    "        else:\n",
    "            df_train = df_train.append(df_temp)\n",
    "\n",
    "    df_test = \"\"\n",
    "    for i in range(19, 23):\n",
    "        print(\"Adding P%i to the test set.\" % (i))\n",
    "        df_temp = pd.read_pickle(datapath + \"p\" + str(i) + \"_blobimages.pkl\", compression=\"gzip\")\n",
    "        if (type(df_test) is str):\n",
    "            df_test = df_temp\n",
    "        else:\n",
    "            df_test = df_test.append(df_temp)\n",
    "            \n",
    "    # Training set        \n",
    "    train_finger = df_train[((df_train.Blobcount == 1) & (df_train.Task.isin(OH_TASKS))) | ((df_train.Blobcount == 2) & (df_train.Task.isin(TH_TASKS)))].BlobImages\n",
    "    train_palm = df_train[(df_train.Blobcount == 1) & (df_train.Task.isin(PALM_TASK))].BlobImages\n",
    "    train_x = []\n",
    "    for i in range(len(train_finger)):\n",
    "        train_x.extend(train_finger.iloc[i])\n",
    "    amount_finger_blobs = len(train_x)\n",
    "    for i in range(len(train_palm)):\n",
    "        train_x.extend(train_palm.iloc[i])\n",
    "    amount_finger_palms = len(train_x) - amount_finger_blobs\n",
    "    print(amount_finger_blobs, amount_finger_palms)\n",
    "    train_y = get_one_hot(np.append(np.zeros(amount_finger_blobs, dtype=np.int), np.ones(amount_finger_palms, dtype=np.int)))\n",
    " \n",
    "\n",
    "    # Test set        \n",
    "    test_finger = df_test[((df_test.Blobcount == 1) & (df_test.Task.isin(OH_TASKS))) | ((df_test.Blobcount == 2) & (df_test.Task.isin(TH_TASKS)))].BlobImages\n",
    "    test_palm = df_test[(df_test.Blobcount == 1) & (df_test.Task.isin(PALM_TASK))].BlobImages\n",
    "    test_x = []\n",
    "    for blobs in test_finger:\n",
    "        test_x.extend(blobs)\n",
    "    amount_finger_blobs = len(test_x)\n",
    "    for blobs in test_palm:\n",
    "        test_x.extend(blobs)\n",
    "    amount_finger_palms = len(test_x) - amount_finger_blobs\n",
    "    test_y = get_one_hot(np.append(np.zeros(amount_finger_blobs, dtype=np.int), np.ones(amount_finger_palms, dtype=np.int)))\n",
    " \n",
    "\n",
    "    # Shuffling the data\n",
    "    print(\"Shuffling training set\")\n",
    "    seed = np.random.randint(0, 21789704)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_y)\n",
    "    print(\"Shuffling test set\")\n",
    "    seed = np.random.randint(0, 21789704)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(test_x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(test_y)\n",
    "    \n",
    "    train_x = np.array(train_x)\n",
    "    test_x = np.array(test_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    print(\"Loading into DataSet objects ...\")\n",
    "    train = DataSet(train_x, train_y, dtype=dtype)\n",
    "    validation = DataSet(test_x, test_y, dtype=dtype)\n",
    "    test = DataSet(test_x, test_y, dtype=dtype)\n",
    "    print(\"Done!\")\n",
    "    return base.Datasets(train=train, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding P1 to the training set.\n",
      "Adding P2 to the training set.\n",
      "Adding P3 to the training set.\n",
      "Adding P4 to the training set.\n",
      "Adding P5 to the training set.\n",
      "Adding P6 to the training set.\n",
      "Adding P7 to the training set.\n",
      "Adding P8 to the training set.\n",
      "Adding P9 to the training set.\n",
      "Adding P10 to the training set.\n",
      "Adding P11 to the training set.\n",
      "Adding P12 to the training set.\n",
      "Adding P13 to the training set.\n",
      "Adding P14 to the training set.\n",
      "Adding P15 to the training set.\n",
      "Adding P16 to the training set.\n",
      "Adding P17 to the training set.\n",
      "Adding P18 to the training set.\n",
      "Adding P19 to the test set.\n",
      "Adding P20 to the test set.\n",
      "Adding P21 to the test set.\n",
      "Adding P22 to the test set.\n",
      "336251 151500\n",
      "Shuffling training set\n",
      "Shuffling test set\n",
      "Loading into DataSet objects ...\n",
      "Done!\n",
      "CPU times: user 32.3 s, sys: 4.61 s, total: 36.9 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = read_data_sets(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image size\n",
    "img_size_hight = data.test.images[0].shape[0]\n",
    "img_size_width = data.test.images[0].shape[1]\n",
    "img_size_flat = img_size_hight * img_size_width\n",
    "img_shape = (img_size_hight, img_size_width)\n",
    "\n",
    "# We have grayscale images\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes (0 = finger; 1 = palm)\n",
    "num_classes = 2\n",
    "\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the best performing hyperparameters as reported in our paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer 1 (7x7x16)\n",
    "filter_size1 = 7  \n",
    "num_filters1 = 16 \n",
    "\n",
    "# Convolution Layer 1 (7x7x36)\n",
    "filter_size2 = 7\n",
    "num_filters2 = 36\n",
    "\n",
    "# Neurons in the fully connected layers\n",
    "fc_size1 = 350\n",
    "fc_size2 = 350\n",
    "\n",
    "# Optimizer settings\n",
    "initial_learning_step = 0.009\n",
    "num_iterations = 1000\n",
    "decay_rate = 0.2\n",
    "\n",
    "# Batch size\n",
    "train_batch_size = 50\n",
    "\n",
    "# GPU Configurations (i.e., restricting the memory use to allow other models to be trained simultaneously)\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=False\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.05\n",
    "config.gpu_options.allocator_type = 'BFC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to create new layers of weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsCounter = -1\n",
    "def new_weights(shape):\n",
    "    #return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    global weightsCounter, GPU_USE\n",
    "    weightsCounter = weightsCounter + 1\n",
    "    return vs.get_variable(\"weights\"+str(weightsCounter), shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "biasesCounter = -1\n",
    "def new_biases(length):\n",
    "    global biasesCounter, GPU_USE\n",
    "    biasesCounter = biasesCounter + 1\n",
    "    return vs.get_variable(\"bias\"+str(biasesCounter), [length], initializer=init_ops.constant_initializer(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to create new convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   layer_name,\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    global GPU_USE\n",
    "    with tf.device(GPU_USE):\n",
    "        # Shape of the filter-weights for the convolution.\n",
    "        # This format is determined by the TensorFlow API.\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights aka. filters with the given shape.\n",
    "        weights = new_weights(shape=shape)\n",
    "\n",
    "        # Create new biases, one for each filter.\n",
    "        biases = new_biases(length=num_filters)\n",
    "\n",
    "        # Create the TensorFlow operation for convolution.\n",
    "        # Note the strides are set to 1 in all dimensions.\n",
    "        # The first and last stride must always be 1,\n",
    "        # because the first is for the image-number and\n",
    "        # the last is for the input-channel.\n",
    "        # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "        # is moved 2 pixels across the x- and y-axis of the image.\n",
    "        # The padding is set to 'SAME' which means the input image\n",
    "        # is padded with zeroes so the size of the output is the same.\n",
    "        \n",
    "        # strides = [batch, height, width, challens]\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME', name=\"conv2d_\" + layer_name)\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        # A bias-value is added to each filter-channel.\n",
    "        layer += biases\n",
    "\n",
    "        # Use pooling to down-sample the image resolution?\n",
    "        if use_pooling:\n",
    "            # This is 2x2 max-pooling, which means that we\n",
    "            # consider 2x2 windows and select the largest value\n",
    "            # in each window. Then we move 2 pixels to the next window.\n",
    "            layer = tf.nn.max_pool(value=layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=\"max_pool_\" + layer_name)\n",
    "\n",
    "        # Rectified Linear Unit (ReLU).\n",
    "        # It calculates max(x, 0) for each input pixel x.\n",
    "        # This adds some non-linearity to the formula and allows us\n",
    "        # to learn more complicated functions.\n",
    "        layer = tf.nn.relu(layer, name=\"relu_\" + layer_name)\n",
    "\n",
    "        # Note that ReLU is normally executed before the pooling,\n",
    "        # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "        # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "        # We return both the resulting layer and the filter-weights\n",
    "        # because we will plot the weights later.\n",
    "        return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to flatten layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to create a new fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "    global GPU_USE\n",
    "    with tf.device(GPU_USE):\n",
    "        # Create new weights and biases.\n",
    "        weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "\n",
    "        # Calculate the layer as the matrix multiplication of\n",
    "        # the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "        # Use ReLU?\n",
    "        if use_relu:\n",
    "            #layer = tf.contrib.layers.batch_norm(layer, center=True, scale=True, is_training=_is_training)\n",
    "            layer = tf.nn.softplus(layer)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "data.train.reset()\n",
    "data.test.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(GPU_USE):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name=\"input_tensor\")\n",
    "    x_image = tf.reshape(x, [-1, img_size_hight, img_size_width, num_channels])\n",
    "    y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "    y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the helper functions to create all layers of the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   layer_name=\"layer_conv1\",\n",
    "                   use_pooling=True)\n",
    "\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   layer_name=\"layer_conv2\",\n",
    "                   use_pooling=True)\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer_conv2)\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size1,\n",
    "                         use_relu=True)\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size2,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(GPU_USE):\n",
    "    y_pred = tf.nn.softmax(layer_fc2, name=\"output_tensor\")\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-function to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(GPU_USE):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(GPU_USE):\n",
    "    decay_steps = num_iterations\n",
    "    _global_step = tf.Variable(0, dtype=tf.int32, name=\"global_step\", trainable=False) \n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_step, _global_step, decay_steps, decay_rate)    \n",
    "    optimizer =  tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(cost)    \n",
    "    \n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting session, TS = 1523550576\n",
      "SAVE_PATH: ./CNN-PalmTouch/1523550576/\n",
      "Epoch:  1, Accuracy: 99.09%, Precision: 99.00%, Recall: 98.05%\n",
      "Epoch:  2, Accuracy: 99.21%, Precision: 98.63%, Recall: 98.84%\n",
      "Epoch:  3, Accuracy: 99.38%, Precision: 99.18%, Recall: 98.80%\n",
      "Epoch:  4, Accuracy: 99.34%, Precision: 98.91%, Recall: 98.96%\n",
      "Epoch:  5, Accuracy: 99.45%, Precision: 99.41%, Recall: 98.83%\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "timestamp = int(time.time())\n",
    "print (\"Starting session, TS = %i\" % timestamp)\n",
    "SAVE_PATH = tensorflowFolder + '/' + STORAGE_NAME + '/'+ str(timestamp) + '/'\n",
    "print (\"SAVE_PATH: %s\" % SAVE_PATH)\n",
    "train_writer = tf.summary.FileWriter(SAVE_PATH, graph=tf.get_default_graph())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.device(GPU_USE):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Start-time used for printing time-usage below.\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            epochs = data.train.epochs_completed\n",
    "            while True:\n",
    "                x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "\n",
    "                x_batch = x_batch.reshape([train_batch_size, x_batch[0].shape[0] * x_batch[0].shape[1]])\n",
    "                feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "\n",
    "                _ = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "                \n",
    "                if epochs != data.train.epochs_completed:    \n",
    "                    break\n",
    "\n",
    "            epochs = data.test.epochs_completed\n",
    "            accs = []\n",
    "            sk_accs = []\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            while True:\n",
    "                x_batch, y_true_batch = data.test.next_batch(train_batch_size)\n",
    "                x_batch = x_batch.reshape([train_batch_size, x_batch[0].shape[0] * x_batch[0].shape[1]])\n",
    "\n",
    "                feed_dict_train = {x: x_batch, y_true: y_true_batch}    \n",
    "                acc, preds = sess.run([accuracy, y_pred], feed_dict=feed_dict_train)\n",
    "                accs.append(acc)\n",
    "                \n",
    "                predictions = np.argmax(preds,1)\n",
    "                precisions.append(precision_score(np.argmax(y_true_batch, 1), predictions))\n",
    "                recalls.append(recall_score(np.argmax(y_true_batch, 1), predictions))\n",
    "                \n",
    "                if epochs != data.test.epochs_completed:    \n",
    "                    break\n",
    "\n",
    "            accs = np.array(accs)\n",
    "            sk_accs = np.array(sk_accs)\n",
    "            precisions = np.array(precisions)\n",
    "            recalls = np.array(recalls)\n",
    "\n",
    "            msg = \"Epoch: {0:>2}, Accuracy: {1:>4.2%}, Precision: {2:>4.2%}, Recall: {3:>4.2%}\"\n",
    "            print (msg.format((i + 1), accs.mean(), precisions.mean(), recalls.mean()))\n",
    "            \n",
    "            op_assign_global_step = _global_step.assign(i)\n",
    "            _ = sess.run([op_assign_global_step])\n",
    "\n",
    "            saver.save(sess, SAVE_PATH + \"model\", global_step=i, write_meta_graph=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
