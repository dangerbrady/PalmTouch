{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Data Frame\n",
    "We read the collected data and store them in a Pandas DataFrame. This makes it easier to filter, process, and split them later on. \n",
    "\n",
    "**NOTE**: Due to the Github space constraints, we did not upload the original data but instead compressed pickle data of already preprocessed touches (i.e., blob images as described in the paper). If you are interested in the original data, please contact Huy.Le@vis.uni-stuttgart.de so we can discuss how we should provide you with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/CapMatrix_P19_C0.txt\n",
      "Reading ./data/CapMatrix_P7_C0.txt\n",
      "Reading ./data/CapMatrix_P21_C0.txt\n",
      "Reading ./data/CapMatrix_P11_C0.txt\n",
      "Reading ./data/CapMatrix_P14_C1.txt\n",
      "Reading ./data/CapMatrix_P3_C1.txt\n",
      "Reading ./data/CapMatrix_P11_C1.txt\n",
      "Reading ./data/CapMatrix_P6_C0.txt\n",
      "Reading ./data/CapMatrix_P2_C1.txt\n",
      "Reading ./data/CapMatrix_P18_C0.txt\n",
      "Reading ./data/CapMatrix_P15_C1.txt\n",
      "Reading ./data/CapMatrix_P17_C0.txt\n",
      "Reading ./data/CapMatrix_P4_C1.txt\n",
      "Reading ./data/CapMatrix_P9_C0.txt\n",
      "Reading ./data/CapMatrix_P8_C1.txt\n",
      "Reading ./data/CapMatrix_P15_C0.txt\n",
      "Reading ./data/CapMatrix_P22_C0.txt\n",
      "Reading ./data/CapMatrix_P10_C0.txt\n",
      "Reading ./data/CapMatrix_P9_C1.txt\n",
      "Reading ./data/CapMatrix_P8_C0.txt\n",
      "Reading ./data/CapMatrix_P4_C0.txt\n",
      "Reading ./data/CapMatrix_P5_C0.txt\n",
      "Reading ./data/CapMatrix_P2_C0.txt\n",
      "Reading ./data/CapMatrix_P5_C1.txt\n",
      "Reading ./data/CapMatrix_P13_C1.txt\n",
      "Reading ./data/CapMatrix_P20_C0.txt\n",
      "Reading ./data/CapMatrix_P13_C0.txt\n",
      "Reading ./data/CapMatrix_P6_C1.txt\n",
      "Reading ./data/CapMatrix_P3_C0.txt\n",
      "Reading ./data/CapMatrix_P10_C1.txt\n",
      "Reading ./data/CapMatrix_P19_C1.txt\n",
      "Reading ./data/CapMatrix_P12_C0.txt\n",
      "Reading ./data/CapMatrix_P14_C0.txt\n",
      "Reading ./data/CapMatrix_P12_C1.txt\n",
      "Reading ./data/CapMatrix_P22_C1.txt\n",
      "Reading ./data/CapMatrix_P16_C0.txt\n",
      "Reading ./data/CapMatrix_P16_C1.txt\n",
      "Reading ./data/CapMatrix_P18_C1.txt\n",
      "Reading ./data/CapMatrix_P1_C0.txt\n",
      "Reading ./data/CapMatrix_P20_C1.txt\n",
      "Reading ./data/CapMatrix_P17_C1.txt\n",
      "Reading ./data/CapMatrix_P7_C1.txt\n",
      "Reading ./data/CapMatrix_P21_C1.txt\n",
      "Reading ./data/CapMatrix_P1_C1.txt\n"
     ]
    }
   ],
   "source": [
    "data = list()\n",
    "lines_skipped = 0\n",
    "\n",
    "DATA_PATH = '../Dataset/'\n",
    "for fn in os.listdir(DATA_PATH):\n",
    "    if os.path.isfile(DATA_PATH + fn):\n",
    "        if (fn.startswith(\"CapMatrix\") and fn.endswith(\".txt\")):\n",
    "            print(\"Reading \" + DATA_PATH + fn)\n",
    "            lines = tuple(open(DATA_PATH + fn, 'r'))\n",
    "            for l in lines:\n",
    "                l = l.split(\";\")\n",
    "                participant  = int(l[0])\n",
    "                condition = int(l[1])\n",
    "                task = l[2]\n",
    "                \n",
    "                kernel_output = l[4]\n",
    "                if (not \",,\" in kernel_output):\n",
    "                    kernel_output = kernel_output.replace(\"\\n\", \"\")\n",
    "                    kernel_output = kernel_output.split(\",\")\n",
    "                    if (len(kernel_output) == 408):\n",
    "                        kernel_output = kernel_output[:407]\n",
    "                        time_ms = float(kernel_output[0])\n",
    "                        time_ns = float(kernel_output[1])\n",
    "                        timestamp = time_ms + time_ns//1000000000\n",
    "                        m_arr = np.array(kernel_output[2:])\n",
    "                        matrix = m_arr.astype(int)\n",
    "                        data.append([participant, condition, task, timestamp, matrix])\n",
    "                    else:\n",
    "                        lines_skipped = lines_skipped + 1\n",
    "                else:\n",
    "                    lines_skipped = lines_skipped + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['Participant', 'Condition', 'Task', 'Timestamp', 'Matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Timestamp = df.Timestamp.astype(int)\n",
    "df.to_pickle(\"./data/data_1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
